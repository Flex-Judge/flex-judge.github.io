<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="Flex-Judge: Text-Only Reasoning Unleashes Zero-Shot Multimodal Evaluators">
  <!-- <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/> -->
  <!-- <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/> -->
  <!-- <meta property="og:url" content="URL OF THE WEBSITE"/> -->
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <!-- <meta property="og:image" content="static/image/your_banner_image.png" /> -->
  <!-- <meta property="og:image:width" content="1200"/> -->
  <!-- <meta property="og:image:height" content="630"/> -->

  <!-- <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG"> -->
  <!-- <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG"> -->
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <!-- <meta name="twitter:image" content="static/images/your_twitter_banner_image.png"> -->
  <!-- <meta name="twitter:card" content="summary_large_image"> -->
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="LLM, Multimodal, Evaluation, Judge">
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <title>Flex-Judge: Text-Only Reasoning Unleashes Zero-Shot Multimodal Evaluators</title>
  <link rel="icon" href="images/flex2.png">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>

  <style>
    /* Custom styles for Flex-Judge examples */
    .example-box {
      background: #fff;
      border-radius: 12px;
      padding: 25px;
      margin: 20px 0;
      box-shadow: 0 4px 15px rgba(0,0,0,0.1);
      border: 1px solid #e8e8e8;
    }

    .label {
      font-weight: bold;
      padding: 8px 16px;
      border-radius: 20px;
      margin: 10px 0 5px 0;
      display: inline-block;
      font-size: 14px;
    }

    .user-label {
      background: #e3f2fd;
      color: #1976d2;
    }

    .judge-label {
      background: #fff3e0;
      color: #f57c00;
    }

    .assistant-label {
      background: #e8f5e8;
      color: #2e7d32;
    }

    .video-assistant {
      background: #e8f5e8;
      color: #2e7d32;
      padding: 6px 12px;
      border-radius: 15px;
      font-weight: bold;
      font-size: 14px;
      display: inline-block;
      margin-top: 8px;
    }

    .label-icon {
      width: 20px;
      height: 20px;
      vertical-align: middle;
      margin-right: 8px;
    }

    .chat-box {
      border-radius: 12px;
      padding: 20px;
      margin: 8px 0 20px 0;
    }

    .user-box {
      background: #f8fbff;
      border: 1px solid #e3f2fd;
      padding: 15px;
    }

    .judge-box {
      background: #fffbf5;
      border: 1px solid #fff3e0;
      padding: 12px;
      max-height: 300px;
      overflow-y: auto;
    }

    .message {
      line-height: 1.6;
      font-size: 15px;
      background: transparent !important;
    }

    .media-row {
      display: flex;
      gap: 20px;
      margin: 10px 0;
      justify-content: center;
    }

    .media-row.single {
      justify-content: flex-start;
      margin: 0;
    }

    .media-row figure {
      flex: 1;
      text-align: center;
      margin: 0;
    }

    .media-row video, .media-row audio {
      width: 100%;
      max-width: 300px;
      height: 200px;
      object-fit: cover;
      border-radius: 8px;
    }

    .audio-inline {
      display: flex;
      align-items: center;
      gap: 10px;
      flex-direction: row;
      margin: 0;
      padding: 0;
    }

    .audio-inline figcaption {
      margin: 0;
      min-width: auto;
      flex-shrink: 0;
    }

    .mos-box {
      background: #f0f8ff;
      border: 2px solid #4CAF50;
      border-radius: 6px;
      padding: 8px 12px;
      margin: 12px 0 4px 0;
      display: inline-block;
      font-weight: bold;
      color: #2E7D32;
      font-size: 14px;
    }

    .mos-value {
      color: #1565C0;
      font-size: 14px;
    }

    .highlight {
      background: #ffeb3b;
      padding: 2px 6px;
      border-radius: 4px;
      font-weight: bold;
    }

    hr {
      margin: 40px 0;
      border: none;
      height: 2px;
      background: linear-gradient(to right, transparent, #ddd, transparent);
    }

    /* Gradient title styling */
    .gradient-title {
      background: linear-gradient(135deg, #667eea 0%, #764ba2 25%, #f093fb 50%, #f5576c 75%, #4facfe 100%);
      background-size: 300% 300%;
      -webkit-background-clip: text;
      -webkit-text-fill-color: transparent;
      background-clip: text;
      animation: gradientShift 4s ease infinite;
    }

    @keyframes gradientShift {
      0% { background-position: 0% 50%; }
      50% { background-position: 100% 50%; }
      100% { background-position: 0% 50%; }
    }
  </style>
</head>
<body>

  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-2 publication-title gradient-title">Flex-Judge: Text-Only Reasoning Unleashes</h1>
            <h1 class="title is-2 publication-title gradient-title">Zero-Shot Multimodal Evaluators</h1>
            <div class="is-size-5">
              <!-- Paper authors -->
              <span class="author-block">
                  <a href="#" style="color:#F2A900;font-weight:normal;">Jongwoo Ko<sup>*</sup></a>,</span>
                <span class="author-block">
                  <a href="#" style="color:#008AD7;font-weight:normal;">Sungnyun Kim<sup>*</sup></a>,</span>
                    <span class="author-block">
                      <a href="#" style="color:#008AD7;font-weight:normal;">Sungwoo Cho</a>,</span>
                    <span class="author-block">
                      <a href="#" style="color:#008AD7;font-weight:normal;">Se-Young Yun</a>
                    </span>
                  </div>

                  <br>
                  <div class="is-size-5 publication-authors">
                    <!-- <span class="author-block"><b style="color:#f68946; font-weight:normal">&#x25B6 </b> Microsoft &nbsp;&nbsp;</span> -->
                    <span class="author-block"><b style="color:#F2A900; font-weight:normal">&#x25B6 </b> Microsoft &nbsp;&nbsp;</span>
                    <span class="author-block"><b style="color:#008AD7; font-weight:normal">&#x25B6 </b> KAIST AI &nbsp;&nbsp;</span>
                  <!-- <br> -->
                    <span class="eql-cntrb" style="font-size: 1.0em;"><sup>*</sup>Equal contribution &nbsp;</span>
                    <!-- <span class="eql-cntrb"><small><sup><span>&#8225;</span></sup>Corresponding author</small></span> -->
                  </div>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                         <!-- Arxiv PDF link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/pdf/2505.18601" target="_blank"
                        class="external-link button is-normal is-rounded is-dark">
                        <span class="icon">
                          <i class="fas fa-file-pdf"></i>
                        </span>
                        <span>Paper</span>
                      </a>
                    </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="https://github.com/jongwooko/flex-judge" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                  </a>
                </span>

                <!-- ArXiv abstract Link -->
                <span class="link-block">
                  <a href="https://arxiv.org/abs/2505.18601" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                    <i class="ai ai-arxiv"></i>
                  </span>
                  <span>arXiv</span>
                </a>
              </span>

                <!-- Hugging Face Models Link -->
                <span class="link-block">
                  <a href="https://huggingface.co/jongwooko/Flex-VL-7B" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <!-- <span class="icon">
                    <i class="fas fa-robot"></i>
                  </span> -->
                  <span>ü§ó Flex-VL-7B</span>
                </a>
              </span>

                                <span class="link-block">
                  <a href="https://huggingface.co/jongwooko/Flex-Omni-7B" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <!-- <span class="icon">
                    <i class="fas fa-robot"></i>
                  </span> -->
                  <span>ü§ó Flex-Omni-7B</span>
                </a>
              </span>

                                <span class="link-block">
                  <a href="https://huggingface.co/sungnyun/Flex-VL-32B-LoRA" target="_blank"
                  class="external-link button is-normal is-rounded is-dark">
                  <!-- <span class="icon">
                    <i class="fas fa-robot"></i>
                  </span> -->
                  <span>ü§ó Flex-VL-32B-LoRA</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Teaser image -->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <img id="teaser" width="150%" src="images/fig_intro.png">
      <h2 class="subtitle has-text-justified">
          <p style="font-family:Times New Roman"><b>Figure 1. Conceptual overview of Flex-Judge. 
            We train a multimodal judge model using a small amount of text-only reasoning data. Unlike previous approaches that require modality-specific supervision, Flex-Judge leverages structured text-only rationale behind judgments to enable generalization across modalities. Once trained, Flex-Judge can be applied to various evaluation tasks, including vision-language tasks, audio quality scoring, and molecular structure, without the need for additional task-specific or modality-specific annotations.</b></p>
      </h2>
    </div>
  </div>
</section>

<!-- Paper abstract -->
<section class="section" style="background-color:#f5f5f5">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>    
            Human-generated reward signals are critical for aligning generative models with human preferences, guiding both training and inference-time evaluations. While large language models (LLMs) employed as proxy evaluators, i.e., LLM-as-a-Judge, significantly reduce the costs associated with manual annotations, they typically require extensive modality-specific training data and fail to generalize well across diverse multimodal tasks. In this paper, we propose <strong>Flex-Judge, a reasoning-guided multimodal judge model that leverages minimal textual reasoning data to robustly generalize across multiple modalities and evaluation formats.</strong> Our core intuition is that structured textual reasoning explanations inherently encode generalizable decision-making patterns, enabling an effective transfer to multimodal judgments, e.g., with images or videos. Empirical results demonstrate that Flex-Judge, despite being trained on significantly fewer text data, achieves competitive or superior performance compared to state-of-the-art commercial APIs and extensively trained multimodal evaluators. Notably, <strong>Flex-Judge presents broad impact in modalities like molecule, where comprehensive evaluation benchmarks are scarce, underscoring its practical value in resource-constrained domains.</strong> Our framework highlights reasoning-based text supervision as a powerful, cost-effective alternative to traditional annotation-intensive approaches, substantially advancing scalable multimodal model-as-a-judge.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Flex-Judge Examples Section -->
<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-five-fifths">
        <h2 class="title is-3">‚öñÔ∏è Flex-Judge Examples </h2> 
      </div>
    </div>

    <!-- Video Examples Section -->
    <section id="video-examples">
      <h2 class="title is-4" style="color:#545454">üé¨ Evaluate Video Generation Task!</h2>
      <div class="example-box">
        <h3><b>Example 1</b></h3>

        <!-- User label -->
        <div class="label user-label">üë§ User</div>
        <!-- User prompt box -->
        <div class="chat-box user-box">
          <div class="message">Generate a video "a donut on the top of broccoli, front view".</div>
        </div>

        <!-- Video comparison -->
        <div class="media-row">
          <figure>
            <video src="media/video1.mp4" controls></video>
            <figcaption><span class="video-assistant">ü§ñ Assistant A</span></figcaption>
          </figure>
          <figure>
            <video src="media/video2.mp4" controls></video>
            <figcaption><span class="video-assistant">ü§ñ Assistant B</span></figcaption>
          </figure>
        </div>

        <!-- Judge label -->
        <div class="label judge-label">
          <img src="images/flex1.png" alt="Judge" class="label-icon">
          Judge
        </div>
        <!-- Judge response box -->
        <div class="chat-box judge-box">
          <div class="message">
            <strong>&lt;think&gt;</strong><br>
              Assistant A's video is quite accurate in terms of the visual representation of the prompt "a donut on the top of broccoli, front view." Here's a detailed breakdown of how the video aligns with the prompt:<br><br>
              
              1. <strong>Alignment with Prompt</strong>: The video clearly shows a donut placed on top of a broccoli floret, which aligns well with the description. The broccoli is in the foreground, and the donut is placed on top, which is consistent with the front view requirement. The donut is also decorated with blue icing, which might be a creative interpretation, but it does not detract from the accuracy in terms of the basic elements (broccoli and donut).<br><br>
              
              2. <strong>Naturalness and Visual Quality</strong>: The broccoli and the donut are both rendered in a way that is somewhat realistic, though the blue icing on the donut might be seen as a creative or artistic choice. The broccoli appears to be a standard broccoli floret, and the donut is depicted in a way that is consistent with typical donut designs, which adds to the naturalness and visual quality of the scene.<br><br>
              
              3. <strong>Consistency and Coherence</strong>: The video maintains a consistent and coherent scene, with the broccoli and donut clearly visible and the donut positioned correctly on top of the broccoli. This coherence is important in maintaining the clarity of the visual representation.<br><br>
              
              4. <strong>Dynamic and Visual Appealing</strong>: The video does not show any dynamic movement, but the still image effectively captures the essence of the prompt. The visual appeal is quite good, with the blue icing on the donut adding a vibrant contrast to the green broccoli, which makes the scene visually interesting.<br><br>
              
              In contrast, let's consider what might be wrong with the video from Assistant B:<br><br>
              
              - <strong>Alignment with Prompt</strong>: The video from Assistant B does not clearly show a donut on top of broccoli. Instead, it appears to show a donut with a broccoli-like texture or a broccoli-shaped donut, which might be a creative interpretation, but it does not align well with the typical understanding of a donut on broccoli. This could be seen as less accurate in terms of the prompt.<br><br>
              
              - <strong>Naturalness and Visual Quality</strong>: The broccoli in the video from Assistant B might be interpreted as a broccoli-shaped donut, which might be a creative interpretation, but it does not clearly represent a broccoli in the traditional sense. This could be seen as less natural in the context of the prompt.<br><br>
              
              - <strong>Consistency and Coherence</strong>: The video from Assistant B might be less coherent in terms of the prompt, as it does not clearly show a donut on top of broccoli. This could lead to confusion or misinterpretation.<br><br>
              
              - <strong>Dynamic and Visual Appealing</strong>: The video from Assistant B might be less visually appealing because the broccoli-like texture on the donut might be less clear or less realistic, which could detract from the overall visual quality.<br><br>
              
              Given these considerations, the video from Assistant A is more accurate in aligning with the prompt, and it maintains a consistent and coherent visual representation, which might be more aligned with the typical understanding of a donut on broccoli. Therefore, it would be more accurate to say that Assistant A's video is better in terms of the prompt's requirements.
              <strong>&lt;/think&gt;</strong><br><br>
              
              <strong>&lt;answer&gt;<span class="highlight">[[A&gt;B]]</span>&lt;/answer&gt;</strong>
          </div>
        </div>
      </div>
    </section>

    <hr>

    <!-- Audio Examples Section -->
    <section id="audio-examples">
      <h2 class="title is-4" style="color:#545454">üîä Evaluate Audio MOS Score!</h2>
      <div class="example-box">
        <h3><b>Example 1</b></h3>

        <!-- User label -->
        <div class="label user-label">üë§ User</div>
        <!-- User prompt box -->
        <div class="chat-box user-box">
          <div class="message">Generate clear, natural, and understandable high-quality speech audio.</div>
        </div>

        <!-- Assistant label -->
        <div class="label assistant-label">ü§ñ Assistant</div>
        <!-- Single audio output -->
        <figure class="audio-inline">
          <audio src="media/audio1.wav" controls></audio>
        </figure>

        <!-- Ground-truth MOS -->
        <div class="mos-box">
          Ground-truth MOS (1-5 scale): <span class="mos-value">4.3</span> 
        </div>
        <br><br>

        <!-- Judge label -->
        <div class="label judge-label">
          <img src="images/flex1.png" alt="Judge" class="label-icon">
          Judge
        </div>
        <!-- Judge response box -->
        <div class="chat-box judge-box">
          <div class="message">
            <strong>&lt;think&gt;</strong><br>
            Assistant's speech is quite clear and understandable, which is a significant improvement over a very bad or poor quality speech. However, the speech is somewhat artificial in tone, which might be a result of the AI's attempt to generate natural speech. Here's a detailed breakdown:<br><br>
            1. <strong>Clarity and Understandability</strong>: The speech provided by the AI is clear and understandable. Each phrase is distinct and easy to follow, which is a good sign. This clarity is a crucial aspect in evaluating the quality of speech generation.<br><br>

            2. <strong>Naturalness</strong>: While the speech is clear, it does not sound entirely natural. The tone and intonation might be slightly robotic or overly mechanical, which can be a sign that the AI might be struggling to fully mimic human speech patterns. This could be due to the limitations in the AI's ability to fully understand and replicate the nuances of human speech.<br><br>

            3. <strong>High-Quality Audio</strong>: The audio quality seems to be good, as the speech is clear and the words are distinct. There are no noticeable distortions or background noises that would detract from the clarity.<br><br>

            4. <strong>Content</strong>: The content of the speech is somewhat abstract and might not be immediately relatable to a typical conversation or narrative. This could be a result of the AI's attempt to generate a specific scenario or narrative, which might not be the most natural or relatable to a human audience.<br><br>

            Given these observations, the speech quality is quite good, but the naturalness could be improved. The clarity and understandability are strong points, but the slight artificiality in the tone might be a drawback.
            <strong>&lt;/think&gt;</strong><br><br>
            
            <strong>&lt;answer&gt;<span class="highlight">4.5</span>&lt;/answer&gt;</strong>
          </div>
        </div>

      </div>

      <div class="example-box">
        <h3><b>Example 2</b></h3>

        <!-- User label -->
        <div class="label user-label">üë§ User</div>
        <!-- User prompt box -->
        <div class="chat-box user-box">
          <div class="message">Generate clear, natural, and understandable high-quality speech audio.</div>
        </div>

        <!-- Assistant label -->
        <div class="label assistant-label">ü§ñ Assistant</div>
        <!-- Single audio output -->
        <figure class="audio-inline">
          <audio src="media/audio2.wav" controls></audio>
          <em>(The audio is very quiet. We recommend volume up.)</em>
        </figure>
        
        <!-- Ground-truth MOS -->
        <div class="mos-box">
          Ground-truth MOS (1-5 scale): <span class="mos-value">1.2</span>
        </div>
        <br><br>

        <!-- Judge label -->
        <div class="label judge-label">
          <img src="images/flex1.png" alt="Judge" class="label-icon">
          Judge
        </div>
        <!-- Judge response box -->
        <div class="chat-box judge-box">
          <div class="message">
            <strong>&lt;think&gt;</strong><br>
            Assistant's answer is significantly flawed in terms of clarity, naturalness, and audio quality, which are the key aspects of the question asked. Here's a detailed breakdown of the issues:<br><br>
            1. <strong>Clarity and Naturalness</strong>: <br>
            - The speech generated by the AI is highly distorted and noisy, making it difficult to understand any specific words or phrases. This is evident from the presence of loud, sharp sounds that do not align with typical speech patterns.<br>   
            - The phrase "rice of third film" does not make sense in a natural or clear context, which suggests that the AI might have misinterpreted or generated nonsensical words.<br><br>
            
            2. <strong>Audio Quality:</strong><br>  
            - The audio quality is extremely poor, with a lot of noise and what appears to be a distorted or malfunctioning sound system. This kind of audio would be difficult to listen to and would likely be considered very bad in terms of audio quality standards.<br><br>
            
            3. <strong>Relevance and Accuracy:</strong><br>   
            - The content "rice of third film" does not seem relevant or accurate to the question asked, which was to generate clear, natural, and understandable speech. This indicates a significant deviation from the intended task, leading to an inaccurate or irrelevant response.<br><br>
            
            Given these issues, it is clear that the speech generated by the AI does not meet the criteria set in the question. The audio is neither clear, natural, nor of high quality, and the content is nonsensical, which would significantly impact the overall score.
            <strong>&lt;/think&gt;</strong><br><br>
            
            <strong>&lt;answer&gt;<span class="highlight">1.0</span>&lt;/answer&gt;</strong>
          </div>
        </div>

      </div>
    </section>

    <hr>

    <!-- Speaker Similarity Examples Section -->
    <section id="speaker-examples">
      <h2 class="title is-4" style="color:#545454">üéôÔ∏è Evaluate Speaker Similarity!</h2>
      <div class="example-box">
        <h3><b>Example 1</b></h3>

        <!-- User label -->
        <div class="label user-label">üë§ User</div>
        <!-- User prompt box -->
        <div class="chat-box user-box">
          <div class="message">Evaluate if these two speech audios share the same speaker.</div>
        </div>

        <!-- Single audio output (inline label) -->
        <figure class="audio-inline">
          <audio src="media/speaker1_1.wav" controls></audio>
          <audio src="media/speaker1_2.wav" controls></audio>
        </figure>
        
        <!-- Ground-truth MOS -->
        <div class="mos-box">
          Ground-truth SS Score (1-6 scale): <span class="mos-value">1.5</span>
        </div>
        <br>

        <div class="mos-box">
          Ground-truth Speaker Match: <span class="mos-value">Not matching</span>
        </div>
        <br><br>

        <!-- User label -->
        <div class="label assistant-label">ü§ñ Assistant</div>
        <!-- User prompt box -->
        <div class="chat-box user-box">
          <div class="message">The given two audios are from the same speaker.</div>
        </div>

        <!-- Judge label -->
        <div class="label judge-label">
          <img src="images/flex1.png" alt="Judge" class="label-icon">
          Judge
        </div>
        <!-- Judge response box -->
        <div class="chat-box judge-box">
          <div class="message">
            <strong>&lt;think&gt;</strong><br>
            Assistant's answer is incorrect. To accurately determine if the two speech audios are from the same speaker, we need to carefully analyze the characteristics such as vocal quality, tone, pitch, accent, and intonation, which are the key factors in distinguishing between different speakers.<br><br>
            
            <strong>Step 1: Analyze Vocal Quality</strong><br>
            - <strong>Audio 1:</strong> The speaker in the first audio has a clear, steady voice with a moderate pitch and a consistent tone. The speech is delivered in a way that suggests a professional or formal setting, which might be indicative of someone who is accustomed to speaking in public or in a professional context.<br>
            - <strong>Audio 2:</strong> The speaker in the second audio has a more casual tone, and the speech is delivered in a more informal manner. This could suggest a different level of comfort or familiarity with the topic being discussed, which might be different from the first audio.<br><br>
            
            <strong>Step 2: Analyze Tone and Pitch</strong><br>
            - <strong>Tone:</strong> The tone in the first audio is steady and professional, which might be expected from someone who is confident and experienced in speaking in a public or professional setting. In contrast, the tone in the second audio is more casual, which might be expected from someone who is more comfortable in a personal or informal setting.<br>
            - <strong>Pitch:</strong> The pitch in both audios seems to be within a similar range, but the tone and delivery might differ significantly, which can be a key factor in distinguishing between speakers.<br><br>
            
            <strong>Step 3: Analyze Accent and Intonation</strong><br>
            - <strong>Accent:</strong> Both audios do not provide clear evidence of a specific accent, but the way the words are pronounced and the intonation might differ. The first audio might have a more formal or professional intonation, while the second audio might have a more casual or informal intonation.<br>
            - <strong>Intonation:</strong> The intonation in the first audio is consistent with a professional or formal speech, whereas the second audio might have a more relaxed or casual intonation, which could be indicative of a different speaker.<br><br>
            
            <strong>Conclusion:</strong><br>
            Given the differences in tone, pitch, and the overall style of speech, it is likely that the two audios are from different speakers. The first audio suggests a more professional or formal speaker, while the second audio suggests a more casual or informal speaker. Therefore, the correct answer would be that the two audios are not from the same speaker.
            <strong>&lt;/think&gt;</strong><br><br>
            
            <strong>&lt;answer&gt;<span class="highlight">2.5</span>&lt;/answer&gt;</strong>
          </div>
        </div>

      </div>

      <div class="example-box">
        <h3><b>Example 2</b></h3>

        <!-- User label -->
        <div class="label user-label">üë§ User</div>
        <!-- User prompt box -->
        <div class="chat-box user-box">
          <div class="message">Evaluate if these two speech audios share the same speaker.</div>
        </div>

        <!-- Single audio output (inline label) -->
        <figure class="audio-inline">
          <audio src="media/speaker2_1.wav" controls></audio>
          <audio src="media/speaker2_2.wav" controls></audio>
        </figure>

        <!-- Ground-truth MOS -->
        <div class="mos-box">
          Ground-truth SS Score (1-6 scale): <span class="mos-value">4.5</span>
        </div>
        <br>

        <div class="mos-box">
          Ground-truth Speaker Match: <span class="mos-value">Matching</span>
        </div>
        <br><br>

        <!-- User label -->
        <div class="label assistant-label">ü§ñ Assistant</div>
        <!-- User prompt box -->
        <div class="chat-box user-box">
          <div class="message">The given two audios are from the same speaker.</div>
        </div>

        <!-- Judge label -->
        <div class="label judge-label">
          <img src="images/flex1.png" alt="Judge" class="label-icon">
          Judge
        </div>
        <!-- Judge response box -->
        <div class="chat-box judge-box">
          <div class="message">
            <strong>&lt;think&gt;</strong><br>
            Assistant's answer is accurate in identifying that the two audio clips are from the same speaker. Here's a detailed analysis of why this conclusion is correct:<br><br>
            
            1. <strong>Voice Characteristics</strong>: Both audio clips feature a female voice, which is a clear indication that the speaker is the same person. The voice quality, tone, and pitch are consistent throughout both clips, suggesting that the speaker is the same individual.<br><br>
            
            2. <strong>Speech Style and Content</strong>: The speech content in both clips is consistent with a narrative or descriptive style, which is typical in interviews or personal stories. Both speakers are discussing personal experiences and future plans, which aligns well with the context provided in the speech subtitles.<br><br>
            
            3. <strong>Emotional Tone</strong>: The emotional tone in both clips is similar, reflecting a mix of excitement and nervousness. This consistency in emotional tone can be a strong indicator that the same person is speaking, as the emotional state often reflects the speaker's personal feelings and experiences.<br><br>
            
            4. <strong>Accent and Intonation</strong>: Both audio clips exhibit a similar accent and intonation, which can be a significant factor in identifying the same speaker. The way the speaker articulates words and the rhythm of speech can be quite distinctive and can help in recognizing the same person.<br><br>
            
            Given these observations, it is reasonable to conclude that the two audio clips are indeed from the same speaker, as the voice characteristics, speech style, emotional tone, and accent all align consistently across both clips.
            <strong>&lt;/think&gt;</strong><br><br>
            
            <strong>&lt;answer&gt;<span class="highlight">4.8</span>&lt;/answer&gt;</strong>
          </div>
        </div>

      </div>
    </section>

    <!-- Note about more examples -->
    <div class="container is-max-desktop" style="margin-top: 30px; margin-bottom: 40px;">
      <div class="columns is-centered">
        <div class="column is-four-fifths has-text-centered">
          <div style="background-color: #f8f9fa; border-left: 4px solid #4CAF50; padding: 20px; border-radius: 8px;">
            <p style="font-style: italic; color: #555; margin: 0;">
              üìñ <strong>Refer to our paper for more examples</strong> across different modalities and evaluation tasks, including image understanding, generation, and editing, and even molecular understanding.
            </p>
          </div>
        </div>
      </div>
    </div>

  </div>
</section>

<!-- Performance Comparison Section -->
<section class="section is-small" style="background-color:#FDF7F0">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-five-fifths">
        <h2 class="title is-3"><i class="fas fa-chart-bar" style="margin-right: 10px; color: #555;"></i> Performance Comparison</h2> 
      </div>
    </div>

    <div class="columns is-centered has-text-centered">
      <div class="column is-six-fifths">
        <div class="content has-text-justified" style="margin-bottom: 30px;">
          <p>We comprehensively evaluate Flex-Judge across diverse modalities, including images, videos, and audio, demonstrating its generalization capability and competitive performance against state-of-the-art judge models. Notably, it matches closed-source commercial APIs on vision tasks and outperforms all training-free evaluators in audio understanding:</p>
        </div>        
        
        <!-- Placeholder for Table 1 -->
        <div style="margin-bottom: 40px;">
          <img id="table1" width="100%" src="images/table1.png" alt="Performance Comparison Table 1">
          <h3 class="subtitle has-text-justified">
            <p style="font-family:Times New Roman"><b>Table 1. Comparison of MLLM evaluator performances on MLLM-as-a-Judge benchmark. Training-free (TF) models have not been trained on multimodal evaluation data.</b></p>
          </h3>
        </div>
        
        <!-- Placeholder for Table 2 -->
        <div style="margin-bottom: 40px;">
          <img id="table2" width="100%" src="images/table2.png" alt="Performance Comparison Table 2">
          <h3 class="subtitle has-text-justified">
            <p style="font-family:Times New Roman"><b>Table 2. Comparison of MLLM evaluator performances on VL-RewardBench (Left) and MJ-Bench(Right).</b></p>
          </h3>
        </div>

        <!-- Placeholder for Table 3 -->
        <div style="margin-bottom: 10px;">
          <img id="table1" width="100%" src="images/table3.png" alt="Performance Comparison Table 1">
          <h3 class="subtitle has-text-justified">
            <p style="font-family:Times New Roman"><b>Table 3. Audio MOS/SS prediction results on NISQA, BVCC, SOMOS, and VoxSim. System-level results are computed by averaging the utterance-level results within each TTS system.</b></p>
          </h3>
        </div>
    </div>
  </div>
</section>

<!-- BibTeX Section -->
<section class="section is-small">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-five-fifths">
        <h2 class="title is-3"><img id="icon" width="3%" src="./static/images/icon-books.png"> BibTeX</h2>
      </div>
    </div>

    <div class="columns is-centered">
      <div class="column is-full-width">        
        <pre style="background-color: #f5f5f5; padding: 20px; border-radius: 8px; text-align: left; font-family: 'SF Mono', Monaco, 'Cascadia Code', 'Roboto Mono', Consolas, monospace; font-size: 15px; line-height: 1.4; overflow-x: auto;">
@article{ko2025flex,
  title={Flex-Judge: Text-Only Reasoning Unleashes Zero-Shot Multimodal Evaluators},
  author={Ko, Jongwoo and Kim, Sungnyun and Cho, Sungwoo and Yun, Se-Young},
  journal={arXiv preprint arXiv:2505.18601},
  year={2025}
}
</pre>
      </div>
    </div>
  </div>
</section>

</body>
</html>